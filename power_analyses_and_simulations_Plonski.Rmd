---
title: "Power Analyses: Wayfinding and Subjective Stress Under Time Pressure"
author: "Paul E. Plonski"
date: "May 16, 2021"
output:
  pdf_document: default
  html_document:
    df_print: paged
subtitle: "Submitted for Graduate Statistics II, Tufts University, Spring 2021"
geometry: margin=1.5cm
---

<br><br>

```{r, echo = FALSE}
# knitr::opts_chunk$set(echo = FALSE, results = "hide", include = FALSE, eval = FALSE)
knitr::opts_chunk$set(echo = FALSE)

```

```{r, message=FALSE}
#### settings ####

# clear workspace  
rm(list=ls(all=TRUE)) 

# set seed
set.seed(44)

# function to detach all non-essential packages (to avoid interference)
detachAllPackages <- function() { 
  # store basic packages' names in a list
  basic.packages <- c("package:stats","package:graphics","package:grDevices",
                      "package:utils","package:dataSets","package:methods",
                      "package:base")  
  # make list of all loaded packages
  package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,
                                  TRUE,
                                  FALSE)]
  # remove basic packages from the list
  package.list <- setdiff(package.list,basic.packages)
  # detach all packages still on the list
  if (length(package.list)>0) {
    for (package in package.list) detach(package, character.only=TRUE)
  }
}
# detach all packages
detachAllPackages()
# remove function
rm(detachAllPackages)

#### load packages ####
# gg plots
library(ggplot2)
# gg themes
library(ggthemes)
# data table
library(data.table)
# type II and III sums of squares
library(car)
# linear mixed models
library(lme4)
# multivariate random samples
library(MASS)
# for printing tables
library(kableExtra)
# for multiple plots
library(egg)
# function to calc the proportion of ps < 0.050
propFun <- function(x){mean(x<.050)}

# set wd
setwd("C:/Dropbox/07 Tufts/Courses/2 - PSY208 (s21)/project")
```
# Part One - Initial Report
## Introduction
This study is designed to test the effects of time pressure on wayfinding in novel, 2-D environments. Wayfinding refers to the planning and decision making aspects of spatial navigation. This study will add to the corpus of research examining the link between time pressure and performance in spatial domains. Importantly, time pressure will be manipulated in three ways to distinguish between the effects temporal constraints, temporal losses, and urgency messaging.  

## Methods
Up to 300 participants will be assigned to one of four groups, in a 2x2 between-subjects design. They will receive either 35 or 25 total minutes to complete the task and have "shorter" or "longer" waiting periods during the task. The design is such that participants in the 35 minute total time condition with long waiting periods will have approximately the same amount of time as participants in the 25 minute total time condition with short waiting periods. A single within-subjects factor will manipulate urgency messaging at the trial level, with approximately half of the trials designated "urgent" and half "not urgent".  
Participants will see a novel 2-D environment during each trial (i.e., an image of a map) with the starting point, ending point, and any waypoints marked. Maps will be shown in a random order and not repeated; participants will complete as many maps as possible in the allotted time. Participants will not all see the same maps, and they may see different numbers of maps.  
The performance outcome used in this project is planning time. This refers to the time that participants spend looking at each map at the beginning of the trial before they begin tracing a route. The hypothesis is that each of the time pressure manipulations, as well as their interactions, will lead to reductions in planning time.  
For this project, all fixed effects and their interactions were simulated as 250ms reductions in planning time and the standard deviation of the residual error was 1000ms. The baseline planning time (with no time pressure manipulations) was simulated as 3000ms. The standard deviations of random intercepts for participants and maps were 500ms. The standard deviation of the random slope (urgency for participants) was 20ms and the correlation between that slope and the random intercept for participants was *r* = -0.3, indicating that for participants with longer planning times to begin with, the effect of urgency messaging would be stronger.

## Data Analysis
The simulated data were analyzed with a linear mixed-effects model. Each of the time pressure manipulations was a fixed effect factor. Random intercepts were included for each participant and each map. The simulated random slope between the random intercept for each participant and the within-subject effect of urgency was not included in the model to prevent overfitting.  

```{r}
#################
# Simulate Data #
#################

#### set parameters ####
# initialize parameter list
params <- list()
# fixed effects intercept
# the mean value at level 1
params$beta.0 <- 3000
# fixed effects slope
# the difference between the mean values of 35 mins and 25 mins
params$beta.1 <- (-250)
# the difference between the mean values of short waits and long waits
params$beta.2 <- (-250)
# the difference between the mean values of urgent and non-urgent trials
params$beta.3 <- (-250)
# slope of the fourth predictor, the interaction between total time and wait time
# the change in the difference between either 35 and 25 minutes with
# a change from short waits to long waits or vice versa
params$beta.4 <- (-250)
# slope of the fifth predictor, the interaction between total time and urgency
# the change in the difference between either 35 and 25 minutes with
# a change from not urgent to urgent or vice versa
params$beta.5 <- (-250)
# slope of the sixth predictor, the interaction between wait time and urgency
# the change in the difference between either short waits and long waits with
# a change from not urgent to urgent or vice versa
params$beta.6 <- (-250)
# slope of the seventh predictor, the interaction between total time, wait time, and urgency
# the change in the difference between either 35 and 25 minutes with
# a change from short waits to long waits and
# a change from not urgent to urgent or vice versa
params$beta.7 <- (-250)
# standard deviation of the first random intercept, participant ID
params$sigma.u.0 <- 500
# standard deviation of the second random intercept, map ID
params$sigma.u.1 <- 500
# standard deviation of the random slope
params$sigma.u.3 <- 20
# correlation between the random intercept for ID the random slope of predictor 3|ID (urgency)
params$cor.u.0.u.3 <- (-0.3)
# standard deviation of the residual errors
params$sigma.epsilon <- 1000
# sample size
params$n <- 300
# number of repetitions per condition
params$n.reps <- 100

# make DT with all combinations of total time & wait time (b/w Ss conditions)
DT.bw.fact <- CJ(totTime = factor(c('35mins','25mins')),
         waitTime = factor(c('shortWaits','longWaits')))
# set the reference levels for the between-subject factors
DT.bw.fact <- within(DT.bw.fact, totTime <- relevel(totTime, ref = '35mins'))
DT.bw.fact <- within(DT.bw.fact, waitTime <- relevel(waitTime, ref = 'shortWaits'))

```

```{r}
#### simulate data ####
# make data.table with b/w Ss conditions and all participant IDs
DT.bw <- cbind(CJ(ID = factor(paste('S', 1:params$n, sep = ''))), DT.bw.fact)
# make DT with all map ID numbers (up to 100) for each Ss
DT.map <- CJ(ID = factor(paste('S', 1:params$n, sep = '')),
             mapID = as.character(factor(paste('Map', 1:params$n.reps))))
# merge the participant ID with b/w Ss conditions and map ID DTs by participant ID
DT.merge <- merge(DT.bw, DT.map, by = "ID")
# make new DT by drawing one random intercept for each map ID and 
# merging with the previous DT that has pID, mapID, and b/w Ss conditions
# - there will be 100 rows for each participant with a random intercept for each map
DT <- merge(DT.merge, 
             data.table(mapID = unique(DT.merge$mapID), 
                        u.1.i = rnorm(params$n.reps, 0, params$sigma.u.1)), 
             by = 'mapID')
# draw a random intercept and a random slope for each participant
# the random slope is for the w/in Ss effect of urgency messaging
DT <- merge(DT, 
            data.table(ID = unique(DT$ID),
                       setNames(data.table(
                         mvrnorm(params$n,
                                 mu = c(0,0),
                                 Sigma=rbind(c(params$sigma.u.0^2, 
                                               params$cor.u.0.u.3 * params$sigma.u.0 *
                                                  params$sigma.u.3),
                                             c(params$cor.u.0.u.3 * params$sigma.u.0 *
                                                  params$sigma.u.3, 
                                               params$sigma.u.3^2)
                                 ))), 
                         c('u.0.i', 'u.3.i'))
            ),
            by = 'ID')
# generate a number of trials completed based on bw Ss conditions
for (i in unique(DT$ID)){
  loopIdData <- DT[which(DT$ID==i),] # row for each pID
  tempTotCond <- loopIdData$totTime[1] # total time condition
  tempWaitCond <- loopIdData$waitTime[1] # wait time condition
  
  # set a random normal number of maps for participant i based on condition
  if (tempTotCond == "35mins" & tempWaitCond == "shortWaits"){
    nummaps <- trunc(rnorm(n=1, mean=49, sd=10))}
  if ((tempTotCond == "35mins" & tempWaitCond == "longWaits") |
      (tempTotCond == "25mins" & tempWaitCond == "shortWaits")){
    nummaps <- trunc(rnorm(n=1, mean=35, sd=10))}
  if (tempTotCond == "25mins" & tempWaitCond == "longWaits"){
    nummaps <- trunc(rnorm(n=1, mean=25, sd=10))
    # adjust the number of maps if rnorm drew less than 5 total maps
    if (nummaps < 5){
      nummaps = rnorm(1,mean=15,sd=2)
    }
    # adjust the number of maps if rnorm or the previous adjustment drew less than 10 total maps
    if (nummaps < 10){
      nummaps <- nummaps*(nummaps/2)
    }
  }
  # add number of maps to column
  DT$nummaps[ DT$ID == i ] <- rep(nummaps,100)
}
# drop trials so each Ss has the correct number of map trials
DT <- subset(DT, as.integer(substr(mapID,5,nchar(mapID))) <= nummaps)
# add the random urgency condition
DT[, urgency_num := (sample(c(0,1), replace=TRUE, size=nrow(DT)))]
# create a factor urgency
DT[, urgency := factor(ifelse(urgency_num==1, 'urgent','not_urgent')),]
# set reference level for urgency
DT$urgency <- factor(DT$urgency, levels = c('not_urgent', 'urgent'))
# this is another way to set levels
## DT$urgency <- relevel(DT$urgency, 'urgent') 
# draw random residuals for every observation
DT[, e.ij := rnorm(.N, 0, params$sigma.epsilon)]
# calculate simulated outcome
DT[, y := abs(params$beta.0 + 
     params$beta.1 * (totTime == '25mins') +
     params$beta.2 * (waitTime == 'longWaits') +
     params$beta.3 * (urgency == 'urgent') +
     params$beta.4 * (totTime == '25mins') * (waitTime == 'longWaits') +
     params$beta.5 * (totTime == '25mins') * (urgency == 'urgent') +
     params$beta.6 * (waitTime == 'longWaits') * (urgency == 'urgent') +
     params$beta.7 * (totTime == '25mins') * (waitTime == 'longWaits') * (urgency == 'urgent') +
     u.0.i + 
     u.1.i +
     u.3.i * (urgency == 'urgent') +   
     e.ij)]
#### fit model ####
# calculate random intercepts model (check estimates of fixed and random effects)
model0 <- lmer(y ~ totTime*waitTime*urgency + (1|ID) + (1|mapID), data = DT)
# store model summary
model.summary <- summary(model0)
# store chi-square tests of significance
model.chisq <- Anova(model0, type = 2)
# remove model from environment
rm(model0)
```

```{r}
#### make a table of LMM output ####

# rename variables in the Anova output
names(model.chisq) <- c("Chisq", "Df", "pvalue")
# make df with model statistics
# format numbers to 2 digits after decimal
# and p-values to publication style 
# !when the matrix is first made!
df.table <- cbind(format(round(model.summary$coefficients[2:8],2), nsmall = 2),
                  format(round(model.chisq$Chisq[1:7],2), nsmall = 2),
                  format.pval(model.chisq$pvalue[1:7], eps = .001, digits = 2))

# set row names
df.table <- cbind(c("Less Total Time (b/w)", "Longer Wait Times (b/w)", "Urgent Message (w/in)",
              "Total Time X Wait Time", "Total Time X Urgency", "Wait Time X Urgency",
              "Total Time X Wait Time X Urgency"), df.table)

# set column names
colnames(df.table) <- c("Predictor", "Coefficient", "Chi-squared", "p-value")
```

## Results
The ICC for the random effect of participant is 0.18 and the ICC for the random effect of map is 0.24 (18% of variability in planning time can be explained by participant ID and 24% by map). The three-way interaction between the time pressure manipulations was not significant, but the two-way interactions were all significant (Table 1). The data and planning time values predicted by the model are plotted in Figure 1, along with group means.  
  
  
Table 1  
```{r}

kbl(df.table, booktabs = T, align = c('r','r','r','r')) %>%
    footnote(general = "Fixed effects and interactions in the linear mixed-effects model.",
             general_title = "Note.", footnote_as_chunk = T)
```


```{r}
#### generate predictions ####
# store estimated fixed and random effects in the data.table
DT[, y.hat := fitted(lmer(y ~ totTime*waitTime*urgency + (1|ID) + (1|mapID), data = DT)) ]

# add a condition variable
DT[, condition := factor(paste(totTime, waitTime, urgency)),]
# set order of factor levels
DT$condition <- factor(DT$condition, 
                       levels = c("35mins shortWaits not_urgent", "35mins shortWaits urgent",
                                  "35mins longWaits not_urgent", "35mins longWaits urgent",
                                  "25mins shortWaits not_urgent", "25mins shortWaits urgent", 
                                  "25mins longWaits not_urgent", "25mins longWaits urgent"))
# rename factor levels for X labels in plotting
levels(DT$condition) <- list("4:NotUrg" = "35mins shortWaits not_urgent",
                             "4:Urg" = "35mins shortWaits urgent",
                             "3:NotUrg" = "35mins longWaits not_urgent",
                             "3:Urg" = "35mins longWaits urgent",
                             "2:NotUrg" = "25mins shortWaits not_urgent",
                             "2:Urg" = "25mins shortWaits urgent",
                             "1:NotUrg" = "25mins longWaits not_urgent",
                             "1:Urg" = "25mins longWaits urgent")

#### aggregate data ####
# aggregate participant data
DT.agg.subj.w <- DT[, list(y.subj.mean = mean(y),
                         y.hat.subj.mean = mean(y.hat)),
                  by = .(ID, totTime, waitTime, urgency)]
# add condition variable (all 6 conditions)
DT.agg.subj.w[, condition := factor(paste(totTime, waitTime, urgency)),]

# aggregate group data
DT.agg.group <- DT.agg.subj.w[, list(y.group.mean = mean(y.subj.mean),
                                   y.hat.group.mean = mean(y.hat.subj.mean)),
                            by = .(totTime, waitTime, urgency)]
# add condition variable (all 6 conditions)
DT.agg.group[, condition := factor(paste(totTime, waitTime, urgency)),]
# set levels for aggregated data
levels(DT.agg.group$condition) <- list("4:NotUrg" = "35mins shortWaits not_urgent",
                                       "4:Urg" = "35mins shortWaits urgent",
                                       "3:NotUrg" = "35mins longWaits not_urgent",
                                       "3:Urg" = "35mins longWaits urgent",
                                       "2:NotUrg" = "25mins shortWaits not_urgent",
                                       "2:Urg" = "25mins shortWaits urgent",
                                       "1:NotUrg" = "25mins longWaits not_urgent",
                                       "1:Urg" = "25mins longWaits urgent")
```

```{r}
#### graphics ####
# set up structure of the plot
gp <- ggplot(DT, aes(x = condition, y = y, 
                     color = condition))
# add a point at each simulated value
gp <- gp + geom_point(size = 2, 
                      position = position_jitter(width = 0.5, 
                                                 seed = 123))
# add a point at each model prediction
gp <- gp + geom_point(aes(y = y.hat), size = 3, shape = 4, 
                      position = position_jitter(width = 0.5, 
                                                 seed = 123))
# add group mean values as segments
gp <- gp + geom_segment(data = DT.agg.group, 
                        mapping=aes(x = condition, y = y.group.mean, 
                                    xend=..x.. + 0.4, yend=..y..),
                        size = 2, color = c('black','black','black','black',
                                            'black','black','black','black'))
# set colors
gp <- gp + scale_color_manual(name = "Condition",
                              labels = c('35/S/NU', '35/S/U',
                                         '35/L/NU', '35/L/U',
                                         '25/S/NU', '25/S/U',
                                         '25/L/NU', '25/L/U'),
                              values = c('blue', 'skyblue', 
                                         'darkgreen', 'palegreen2',
                                         'gold', 'sienna1',
                                         'red', 'pink2'))
# add labels
gp <- gp + xlab("Condition")
gp <- gp + ylab("Planning Time")
# add caption
gp <- gp + labs(caption = "Planning time for each time pressure condition. \n
                Group 4: More total time, shorter waits \n
                Group 3: More total time, longer waits \n
                Group 2: Less total time, shorter waits \n
                Group 1: Less total time, longer waits")
# add theme and font size
gp <- gp + theme_bw(14)
# remove ugly lines
gp <- gp + theme(axis.ticks = element_blank(),
                 panel.border = element_blank(),
                 panel.grid.minor = element_blank(),
                 panel.grid.major.x = element_blank(),
                 plot.caption = element_text(hjust = 0, lineheight = 0.5))
# move legend
gp <- gp + theme(legend.position = 'right')
```
Figure 1  
```{r fig.width=7, fig.height=3}
# show plot
print(gp)
```

## Discussion
The results indicate interactive effects between each pair of time pressure manipulations. The shortest planning time appears in the condition with less total time, longer wait times, and in the presence of external urgency messaging. However, the three-way interaction between total time, waiting time, and urgency messaing was not significant.


# Part Two - Simulation Report
## Simulation One
The first simulation used the same parameters as part one. Four sample sizes were simulated; *N* = 30 corresponds to a pilot sample and *N* = 300 corresponds to the proposed sample. The purpose of the simulation was primarily to determine the power to detect a significant two-way interaction between total time and waiting time and a significant three-way interaction between total time, waiting time, and urgency messaging. The secondary purpose of the simulation was to determine the estimation error for those same two interaction effects.  
The main effects of each time pressure manipulation appeared in roughly 80% or more of the simulations for all four sample sizes (i.e., there was adequate power) (Table 2). The two-way interaction between the between-subjects effects was nearly adequately powered with *N* = 300 (76%). The two-way interactions between either total time or wait time (between-subjects) and urgency (within-subjects) were significant more often than the two-way interaction between the between-subjects effects. The three-way interaction was not adequately powered for any of the sample sizes. Figure 2 displays the number of significant *p*-values for the between-subjects interaction of total time and waiting time and the three-way interaction of the time pressure manipulations.  
The estimation error is relatively close to zero for all effects except the three-way interaction between the time pressure manipulations. The three-way interaction is consistently biased upwards, regardless of sample size. Figure 3 displays the estimation error for each simulation of the two interactions. Table 3 contains the average estimation error.  
```{r}
################
# SIMULATION 1 #
################
#### function to simulate data ####
###############################################
# With Random Slope for Participant ~ Urgency #
###############################################
LMM.sim.slope <- function(DT.bw.fact, params, n){
  
# make DT with bw Ss conditions and IDs
suppressWarnings(DT.bw <- cbind(CJ(ID = factor(paste('S', 1:n, sep = ''))), DT.bw.fact))

# make DT with all map numbers for each Ss
DT.map <- CJ(ID = factor(paste('S', 1:n, sep = '')),
             mapID = as.character(factor(paste('Map', 1:params$n.reps))))

# merge DT bw and DT maps
DT.merge <- merge(DT.bw, DT.map, by = "ID")
  
# draw one random intercept for each mapID and add it to the data.table
# by using merge the one random intercept per mapID will be added to each
# observation belonging to that mapID
DT <- merge(DT.merge, 
             data.table(mapID = unique(DT.merge$mapID), 
                        u.1.i = rnorm(params$n.reps, 0, params$sigma.u.1)), 
             by = 'mapID')
# draw one random intercept and one random slope from a multivariate normal dist
# for each pID and add it to the data.table
# by using merge the one random intercept and slope per pID will be added to each
# observation belonging to that participant
DT <- merge(DT, 
           data.table(ID = unique(DT$ID),
                      setNames(data.table(
                        mvrnorm(n,
                                mu = c(0,0),
                                Sigma=rbind(c(params$sigma.u.0^2, 
                                              params$cor.u.0.u.3 * params$sigma.u.0 *
                                                 params$sigma.u.3),
                                            c(params$cor.u.0.u.3 * params$sigma.u.0 *
                                                 params$sigma.u.3, 
                                              params$sigma.u.3^2)
                                ))), 
                        c('u.0.i', 'u.3.i'))
           ),
           by = 'ID')
 
# generate a number of trials completed based on bw Ss conditions
for (i in unique(DT$ID)){
   loopIdData <- DT[which(DT$ID==i),]
   tempTotCond <- loopIdData$totTime[1]
   tempWaitCond <- loopIdData$waitTime[1]
   
   # set a random normal number of maps for participant i based on condition
   if (tempTotCond == "35mins" & tempWaitCond == "shortWaits"){
     nummaps <- trunc(rnorm(n=1, mean=49, sd=10))}
   if ((tempTotCond == "35mins" & tempWaitCond == "longWaits") |
       (tempTotCond == "25mins" & tempWaitCond == "shortWaits")){
     nummaps <- trunc(rnorm(n=1, mean=35, sd=10))}
   if (tempTotCond == "25mins" & tempWaitCond == "longWaits"){
     nummaps <- trunc(rnorm(n=1, mean=25, sd=10))
     # if map number is too low, set it higher
     if (nummaps < 5){
       nummaps = rnorm(1,mean=15,sd=2)
     }
    # if the random higher is still too low, one more time
    if (nummaps < 10){
      nummaps <- nummaps*(nummaps/2)
 }
}
# add a number of maps to column
DT$nummaps[ DT$ID == i ] <- rep(nummaps,100)

}

# drop trials so each Ss has the correct number of map trials
DT <- subset(DT, as.integer(substr(mapID,5,nchar(mapID))) <= nummaps)

# add the urgency condition
DT[, urgency_num := (sample(c(0,1), replace=TRUE, size=nrow(DT)))]

# create a factor urgency
DT[, urgency := factor(ifelse(urgency_num==1, 'urgent','not_urgent')),]
# set the reference level for urgency
DT$urgency <- factor(DT$urgency, levels = c('not_urgent', 'urgent'))

# draw random residuals for every observation
DT[, e.ij := rnorm(.N, 0, params$sigma.epsilon)]
# calculate simulated outcome
DT[, y := abs(params$beta.0 + 
     params$beta.1 * (totTime == '25mins') +
     params$beta.2 * (waitTime == 'longWaits') +
     params$beta.3 * (urgency == 'urgent') +
     params$beta.4 * (totTime == '25mins') * (waitTime == 'longWaits') +
     params$beta.5 * (totTime == '25mins') * (urgency == 'urgent') +
     params$beta.6 * (waitTime == 'longWaits') * (urgency == 'urgent') +
     params$beta.7 * (totTime == '25mins') * (waitTime == 'longWaits') * (urgency == 'urgent') +
     u.0.i + 
     u.1.i +
     u.3.i * (urgency == 'urgent') +
     e.ij)]


#### fit model to the simulated data ####

#### estimate the model of the simulated data ####

# the models can fail to converge, thus, they are wrapped in a try and catch block
tryCatch(
  {
    # calculate random intercept model (check estimates of fixed and random effects)
    lmermodel <- lmer(y ~ totTime*waitTime*urgency + (1|ID) + (1|mapID), data = DT)
    #print(linearMixedEffectsModel <- lmer(y ~ x1 * x2 + (x1 + x2 | ID), data = DT))
  },
  # in case that an error occurred, the model could would not even be estimated
  error = function() {
    # write out error message
    message("The model could not be estimated. Collect more data!")
  }
)

# check if the model was calculated
if (exists('lmermodel')) {
  # check for the absence of warning messages
  if (is.null(lmermodel@optinfo$conv$lme4$messages)){
    # model evaluation 1
    #print(summary(lmermodel))
    # model evaluation 2
    #print(Anova(lmermodel))
    # store estimated data in the data.table
    DT[, y.hat := fitted(lmermodel)]
    # check for a singular fit
  } else if (is.null(lmermodel@optinfo$conv$lme4$code)){
    # check for singular fit
    if (lmermodel@optinfo$conv$lme4$messages == "boundary (singular) fit: see ?isSingular") {
      # write out error message
      message("The model is singular, the random effects are too complex to be fitted. Collect more data!")
      # store NAs rather than the fitted data
      DT[, y.hat := NA]
    } else {
      # write out error message
      message("You are having problems I did not foresee!")
      # store NAs rather than the fitted data
      DT[, y.hat := NA]
    }
    # check for further convergence issues
  } else if (lmermodel@optinfo$conv$lme4$code == -1){
    # model evaluation 1
    #print(summary(lmermodel))
    # model evaluation 2
    #print(Anova(lmermodel))
    # store estimated data in the data.table
    DT[, y.hat := fitted(lmermodel)]
    # write out warning message
    message("There are convergence issues. Try to rescale the data or collect more data!")
  } else {
    # write out error message
    message("You are having problems I did not foresee!")
    # store NAs rather than the fitted data
    DT[, y.hat := NA]
  }
} else { # if the model does not exist
  # store NAs rather than the fitted data
  DT[, y.hat := NA]
}

lmer.eval <- summary(lmermodel)
lmer.chisq <- Anova(lmermodel)

# store parameters of interest from simulation and original values
# combine with previous simulation results
temp_list <- list(
  totTime.estimate = lmer.eval$coefficients[2],
  totTime.t.value = lmer.eval$coefficients[2, "t value"],
  totTime.p.value = lmer.chisq$`Pr(>Chisq)`[1],
  
  waitTime.estimate = lmer.eval$coefficients[3],
  waitTime.t.value = lmer.eval$coefficients[3, "t value"],
  waitTime.p.value = lmer.chisq$`Pr(>Chisq)`[2],
  
  urgency.estimate = lmer.eval$coefficients[4],
  urgency.t.value = lmer.eval$coefficients[4, "t value"],
  urgency.p.value = lmer.chisq$`Pr(>Chisq)`[3],
  
  totXwait.estimate = lmer.eval$coefficients[5],
  totXwait.t.value = lmer.eval$coefficients[5, "t value"],
  totXwait.p.value = lmer.chisq$`Pr(>Chisq)`[4],
  
  totXurg.estimate = lmer.eval$coefficients[6],
  totXurg.t.value = lmer.eval$coefficients[6, "t value"],
  totXurg.p.value = lmer.chisq$`Pr(>Chisq)`[5],
  
  waitXurg.estimate = lmer.eval$coefficients[7],
  waitXurg.t.value = lmer.eval$coefficients[7, "t value"],
  waitXurg.p.value = lmer.chisq$`Pr(>Chisq)`[6],
  
  totXwaitXurg.estimate = lmer.eval$coefficients[8],
  totXwaitXurg.t.value = lmer.eval$coefficients[8, "t value"],
  totXwaitXurg.p.value = lmer.chisq$`Pr(>Chisq)`[7],
  
  sigma.estimate = lmer.eval$sigma
)

}
```

```{r eval = F}
# sample sizes
params$n.set <- c(30, 200, 300, 400)
# store the number of repetitions for the simulation (should usually be around 10.000)
params$n.sims <- 1000

# create data.table where each row is one simulation for one parameter values of interest
DT.sim.results <- CJ(sim.no = 1:params$n.sims,
                     n = params$n.set)
                     
# for each simulation and sample size call the function to do the simulation
DT.sim.results[, c('totTime.estimate', 'totTime.t.value', 'totTime.p.value',
                   'waitTime.estimate', 'waitTime.t.value', 'waitTime.p.value',
                   'urgency.estimate', 'urgency.t.value', 'urgency.p.value',
                   'totXwait.estimate', 'totXwait.t.value', 'totXwait.p.value',
                   'totXurg.estimate', 'totXurg.t.value', 'totXurg.p.value',
                   'waitXurg.estimate', 'waitXurg.t.value', 'waitXurg.p.value',
                   'totXwaitXurg.estimate', 'totXwaitXurg.t.value', 'totXwaitXurg.p.value',
                   'sigma.estimate') := 
                 LMM.sim.slope(DT.bw.fact = DT.bw.fact, 
                               params = params, n = n), 
               by = .(sim.no, n)]
# calculate estimation errors
DT.sim.results[, ':=' (totTime_estimation_error = totTime.estimate - params$beta.1,
                       waitTime_estimation_error = waitTime.estimate - params$beta.2,
                       urgency_estimation_error = urgency.estimate - params$beta.3,
                       totXwait_estimation_error = totXwait.estimate - params$beta.4,
                       totXurg_estimation_error = totXurg.estimate - params$beta.5,
                       waitXurg_estimation_error = waitXurg.estimate - params$beta.6,
                       totXwaitXurg_estimation_error = totXwaitXurg.estimate - params$beta.7,
                       sigma_estimation_error = sigma.estimate - params$sigma.epsilon)]

# save simulated data
#write.csv(DT.sim.results, "DT_simresults.csv")
```

```{r}
# set wd
# setwd()
# load data simulated with the random slope and -0.3 correlation b/w
# participant random intercept and random slope of urgency
DT.sim.results <- data.table(read.csv("DT_simresults.csv"))
# set a factor to plot by sample size
DT.sim.results[, n_fact := factor(n),]
# calc average estimation errors
DT.summary.error <- DT.sim.results[, lapply(.SD, mean), 
                                   .SDcols = c("totTime_estimation_error",
                                               "waitTime_estimation_error",
                                               "urgency_estimation_error",
                                               "totXwait_estimation_error",
                                               "totXurg_estimation_error",
                                               "waitXurg_estimation_error",
                                               "totXwaitXurg_estimation_error",
                                               "sigma_estimation_error"),
                                   by = n]


# calc proportions of significant p values
DT.summary.props <- DT.sim.results[, lapply(.SD, propFun),
                                   .SDcols = c("totTime.p.value",
                                               "waitTime.p.value",
                                               "urgency.p.value",
                                               "totXwait.p.value",
                                               "totXurg.p.value",
                                               "waitXurg.p.value",
                                               "totXwaitXurg.p.value"),
                                   by = n]
```

Table 2
```{r}
df.sim1.p.table <- format(round(DT.summary.props,2), nsmall=2)
# set column names
colnames(df.sim1.p.table) <- c("Sample Size", "Total Time", "Wait Time", "Urgency",
                               "TotalxWait", "TotalxUrg", "WaitxUrg", "TotalxWaitxUrg")
# table of p value proportions
kbl(df.sim1.p.table, booktabs = T, align = c('r','r','r','r')) %>%
    footnote(general = "Proportion of significant p-values in 1000 simulations",
             general_title = "Note.", footnote_as_chunk = T)

```

```{r}
### two-way interaction p-values ###
# ggplot data layer
gp.hist.2way <- ggplot(DT.sim.results)
# add histograms
gp.hist.2way <- gp.hist.2way + geom_histogram(position = "dodge", bins = 15,
                                              aes(x = totXwait.p.value, 
                                                  fill = n_fact))
# add vert line for sig value
gp.hist.2way <- gp.hist.2way + geom_vline(aes(xintercept = 0.05), 
                                          color = "red", size = 1) 
# add horizontal line for number of p-values expected w/o effect
gp.hist.2way <- gp.hist.2way + geom_hline(aes(yintercept = (1000*0.05)), 
                                          color = "blue", size = 1) 
# set theme tufte
gp.hist.2way <- gp.hist.2way + theme_tufte(base_size = 11, base_family = "sans") 
# format legend and colors
gp.hist.2way <- gp.hist.2way + scale_fill_manual(name = "Sample Size",
                              labels = c('N = 30',
                                         'N = 200',
                                         'N = 300',
                                         'N = 400'),
                              values = c('lightblue', 'palegreen',
                                         'gold', 'pink2'))
# add axis labels
gp.hist.2way <- gp.hist.2way + xlab("Total Time x Wait Time Interaction")
gp.hist.2way <- gp.hist.2way + ylab("Number of Significant P-values")
# add caption
gp.hist.2way <- gp.hist.2way + labs(caption = 
      "Of 1000 simulations, the number of significant p-values for each sample size. \n
      Simulations to the left of the red line are significant. \n
      The blue line is the expected number of significant p-values if there were no effect.")
# align caption
gp.hist.2way <- gp.hist.2way + theme(plot.caption = element_text(hjust = 0, lineheight = 0.5))
```

```{r}
### three-way interaction p-values ###
# ggplot data layer
gp.hist.3way <- ggplot(DT.sim.results)
# add histograms
gp.hist.3way <- gp.hist.3way + geom_histogram(position = "dodge", bins = 15,
                                              aes(x = totXwaitXurg.p.value,
                                                  fill = n_fact))
# add vert line for sig value
gp.hist.3way <- gp.hist.3way + geom_vline(aes(xintercept = 0.05), 
                                          color = "red", size = 1) 
# add horizontal line for number of p-values expected w/o effect
gp.hist.3way <- gp.hist.3way + geom_hline(aes(yintercept = (1000*0.05)), 
                                          color = "blue", size = 1) 
# set theme tufte
gp.hist.3way <- gp.hist.3way + theme_tufte(base_size = 11, base_family = "sans") 
# format legend and colors
gp.hist.3way <- gp.hist.3way + scale_fill_manual(name = "Sample Size",
                              labels = c('N = 30',
                                         'N = 200',
                                         'N = 300',
                                         'N = 400'),
                              values = c('lightblue', 'palegreen',
                                         'gold', 'pink2'))
# add axis labels
gp.hist.3way <- gp.hist.3way + xlab("Total Time x Wait Time x Urgency Interaction")
gp.hist.3way <- gp.hist.3way + ylab("Number of Significant P-values")
# add caption
gp.hist.3way <- gp.hist.3way + labs(caption = 
      "Of 1000 simulations, the number of significant p-values for each sample size. \n
      Simulations to the left of the red line are significant. \n
      The blue line is the expected number of significant p-values if there were no effect.")
# align caption
gp.hist.3way <- gp.hist.3way + theme(plot.caption = element_text(hjust = 0, lineheight = 0.5))
```
Figure 2  

```{r fig.width=7, fig.height=6}
ggarrange(gp.hist.2way, gp.hist.3way)
```


```{r}
### 2-way effect ###
gp.violin.esti2.sim1 <- ggplot(DT.sim.results, aes(x = n_fact, y = totXwait_estimation_error))

gp.violin.esti2.sim1 <- gp.violin.esti2.sim1 + geom_violin()
# add data
gp.violin.esti2.sim1 <- gp.violin.esti2.sim1 + geom_jitter(width = 0.1, 
                                                           alpha = 0.25, 
                                                           colour = 'blue')
# add horizontal line at 0
gp.violin.esti2.sim1 <- gp.violin.esti2.sim1 + geom_hline(aes(yintercept = 0), 
                                                        color = "black", size = 1)
# add axis labels
gp.violin.esti2.sim1 <- gp.violin.esti2.sim1 + ylab('Estimation Error for Total Time x Wait Time')
gp.violin.esti2.sim1 <- gp.violin.esti2.sim1 + xlab('Sample Size')
# add caption
gp.violin.esti2.sim1 <- gp.violin.esti2.sim1 + labs(caption = 
      "Estimation error for 1000 simulations of each sample size.")
# set theme
gp.violin.esti2.sim1 <- gp.violin.esti2.sim1 + theme_tufte(base_size = 11, base_family = "sans")
# align caption
gp.violin.esti2.sim1 <- gp.violin.esti2.sim1 + theme(plot.caption = element_text(hjust = 0))
# set coord
gp.violin.esti2.sim1 <- gp.violin.esti2.sim1 + coord_cartesian(ylim = c(-1200,1400))
```

```{r}
### 3-way effect ###
gp.violin.esti3.sim1 <- ggplot(DT.sim.results, aes(x = n_fact, y = totXwaitXurg_estimation_error))

gp.violin.esti3.sim1 <- gp.violin.esti3.sim1 + geom_violin()
# add data
gp.violin.esti3.sim1 <- gp.violin.esti3.sim1 + geom_jitter(width = 0.1, 
                                                           alpha = 0.25,
                                                           colour = 'blue')
# add horizontal line at 0
gp.violin.esti3.sim1 <- gp.violin.esti3.sim1 + geom_hline(aes(yintercept = 0), 
                                                        color = "black", size = 1)
# add axis labels
gp.violin.esti3.sim1 <- gp.violin.esti3.sim1 + ylab('Estimation Error for Total Time x Wait Time x Urgency')
gp.violin.esti3.sim1 <- gp.violin.esti3.sim1 + xlab('Sample Size')

# set theme
gp.violin.esti3.sim1 <- gp.violin.esti3.sim1 + theme_tufte(base_size = 11, base_family = "sans")
# align caption
gp.violin.esti3.sim1 <- gp.violin.esti3.sim1 + theme(plot.caption = element_text(hjust = 0))
# set coord
gp.violin.esti3.sim1 <- gp.violin.esti3.sim1 + coord_cartesian(ylim = c(-1200,1400))
```
  
  
  
  
Figure 3

```{r fig.width=7, fig.height=4}
ggarrange(gp.violin.esti2.sim1, gp.violin.esti3.sim1, ncol = 2)
```
Table 3
```{r}
df.sim1.est.table <- round(DT.summary.error,2)
# set column names
colnames(df.sim1.est.table) <- c("Sample Size", "Total Time", "Wait Time", "Urgency",
                               "TotalxWait", "TotalxUrg", "WaitxUrg", "TotalxWaitxUrg",
                               "Residual")
# table of p value proportions
kbl(df.sim1.est.table, booktabs = T, align = c('r','r','r','r')) %>%
    footnote(general = "Mean Estimation Error in 1000 simulations",
             general_title = "Note.", footnote_as_chunk = T)

```


## Simulation Two
The second simulation was designed to test whether the results of the first simulation would be consistent if there was in fact no random slope for urgency by participant (and therefore, no correlation between the random intercept for participant and the degree to which they are affected by urgency messaging). There were no noteworthy differences between the proportion of significant *p*-values or estimation errors between the two simulations, although there seemed be less estimation error (Figure 4), especially at the pilot sample size (*N* = 30), if the random slope was not simulated. Table 4 contains the proportion of significant *p*-values and Table 5 contains the average estimation error.  

```{r}
################
# SIMULATION 2 #
################
#### function to simulate data ####
###############################################
#  No Random Slope for Participant ~ Urgency  #
###############################################
LMM.sim.noslope <- function(DT.bw.fact, params, n){
  
  
  # make DT with bw Ss conditions and IDs
  suppressWarnings(DT.bw <- cbind(CJ(ID = factor(paste('S', 1:n, sep = ''))), DT.bw.fact))
  
  # make DT with all map numbers for each Ss
  DT.map <- CJ(ID = factor(paste('S', 1:n, sep = '')),
               mapID = as.character(factor(paste('Map', 1:params$n.reps))))
  
  # merge DT bw conditions & DT map
  DT.merge <- merge(DT.bw, DT.map, by = "ID")
    # draw one random intercept for each mapID and add it to the data.table
  # by using merge the one random intercept per mapID will be added to each
  # observation belonging to that mapID
  DT <- merge(DT.merge, 
              data.table(mapID = unique(DT.merge$mapID), 
                         u.1.i = rnorm(params$n.reps, 0, params$sigma.u.1)), 
              by = 'mapID')
    # draw one random intercept for each pID and add it to the data.table
  # by using merge the one random intercept per pID will be added to each
  # observation belonging to that participant
  suppressWarnings(DT <- merge(DT, 
              data.table(ID = unique(DT$ID),
                         u.0.i = rnorm(params$n.reps, 0, params$sigma.u.0)),
              by = 'ID', allow.cartesian=TRUE))
  
  # generate a number of trials completed based on bw Ss conditions
  for (i in unique(DT$ID)){
    loopIdData <- DT[which(DT$ID==i),]
    tempTotCond <- loopIdData$totTime[1]
    tempWaitCond <- loopIdData$waitTime[1]
    
    # set a random normal number of maps for participant i based on condition
    if (tempTotCond == "35mins" & tempWaitCond == "shortWaits"){
      nummaps <- trunc(rnorm(n=1, mean=49, sd=10))}
    if ((tempTotCond == "35mins" & tempWaitCond == "longWaits") |
        (tempTotCond == "25mins" & tempWaitCond == "shortWaits")){
      nummaps <- trunc(rnorm(n=1, mean=35, sd=10))}
    if (tempTotCond == "25mins" & tempWaitCond == "longWaits"){
      nummaps <- trunc(rnorm(n=1, mean=25, sd=10))
      # if map number is too low, set it higher
      if (nummaps < 5){
        nummaps = rnorm(1,mean=15,sd=2)
      }
      # if the random higher is still too low, one more time
      if (nummaps < 10){
        nummaps <- nummaps*(nummaps/2)
      }
    }
    # add a number of maps column
    DT$nummaps[ DT$ID == i ] <- rep(nummaps,100)
    
  }
  
  # drop trials so each Ss has the correct number of map trials
  DT <- subset(DT, as.integer(substr(mapID,5,nchar(mapID))) <= nummaps)
  
  # add the urgency condition
  DT[, urgency_num := (sample(c(0,1), replace=TRUE, size=nrow(DT)))]
  
  # create a factor urgency
  DT[, urgency := factor(ifelse(urgency_num==1, 'urgent','not_urgent')),]
  # set the reference level for urgency
  DT$urgency <- factor(DT$urgency, levels = c('not_urgent', 'urgent'))
  
  # draw random residuals for every observation
  DT[, e.ij := rnorm(.N, 0, params$sigma.epsilon)]
  # calculate simulated outcome
  DT[, y := abs(params$beta.0 + 
                  params$beta.1 * (totTime == '25mins') +
                  params$beta.2 * (waitTime == 'longWaits') +
                  params$beta.3 * (urgency == 'urgent') +
                  params$beta.4 * (totTime == '25mins') * (waitTime == 'longWaits') +
                  params$beta.5 * (totTime == '25mins') * (urgency == 'urgent') +
                  params$beta.6 * (waitTime == 'longWaits') * (urgency == 'urgent') +
                  params$beta.7 * (totTime == '25mins') * (waitTime == 'longWaits') * (urgency == 'urgent') +
                  u.0.i + 
                  u.1.i +
                  e.ij)]
  
  
  #### fit model to the simulated data ####
  
  #### estimate the model of the simulated data ####
  
  # the models can fail to converge, thus, they are wrapped in a try and catch block
  tryCatch(
    {
      # calculate random intercept model (check estimates of fixed and random effects)
      lmermodel <- lmer(y ~ totTime*waitTime*urgency + (1|ID) + (1|mapID), data = DT)
      #print(linearMixedEffectsModel <- lmer(y ~ x1 * x2 + (x1 + x2 | ID), data = DT))
    },
    # in case that an error occurred, the model could would not even be estimated
    error = function() {
      # write out error message
      message("The model could not be estimated. Collect more data!")
    }
  )
  
  # check if the model was calculated
  if (exists('lmermodel')) {
    # check for the absence of warning messages
    if (is.null(lmermodel@optinfo$conv$lme4$messages)){
      # model evaluation 1
      #print(summary(lmermodel))
      # model evaluation 2
      #print(Anova(lmermodel))
      # store estimated data in the data.table
      DT[, y.hat := fitted(lmermodel)]
      # check for a singular fit
    } else if (is.null(lmermodel@optinfo$conv$lme4$code)){
      # check for singular fit
      if (lmermodel@optinfo$conv$lme4$messages == "boundary (singular) fit: see ?isSingular") {
        # write out error message
        message("The model is singular, the random effects are too complex to be fitted. Collect more data!")
        # store NAs rather than the fitted data
        DT[, y.hat := NA]
      } else {
        # write out error message
        message("You are having problems I did not foresee!")
        # store NAs rather than the fitted data
        DT[, y.hat := NA]
      }
      # check for further convergence issues
    } else if (lmermodel@optinfo$conv$lme4$code == -1){
      # model evaluation 1
      #print(summary(lmermodel))
      # model evaluation 2
      #print(Anova(lmermodel))
      # store estimated data in the data.table
      DT[, y.hat := fitted(lmermodel)]
      # write out warning message
      message("There are convergence issues. Try to rescale the data or collect more data!")
    } else {
      # write out error message
      message("You are having problems I did not foresee!")
      # store NAs rather than the fitted data
      DT[, y.hat := NA]
    }
  } else { # if the model does not exist
    # store NAs rather than the fitted data
    DT[, y.hat := NA]
  }
  
  lmer.eval <- summary(lmermodel)
  lmer.chisq <- Anova(lmermodel)
  
  # store parameters of interest from simulation and original values
  # combine with previous simulation results
  temp_list <- list(
    totTime.estimate = lmer.eval$coefficients[2],
    totTime.t.value = lmer.eval$coefficients[2, "t value"],
    totTime.p.value = lmer.chisq$`Pr(>Chisq)`[1],
    
    waitTime.estimate = lmer.eval$coefficients[3],
    waitTime.t.value = lmer.eval$coefficients[3, "t value"],
    waitTime.p.value = lmer.chisq$`Pr(>Chisq)`[2],
    
    urgency.estimate = lmer.eval$coefficients[4],
    urgency.t.value = lmer.eval$coefficients[4, "t value"],
    urgency.p.value = lmer.chisq$`Pr(>Chisq)`[3],
    
    totXwait.estimate = lmer.eval$coefficients[5],
    totXwait.t.value = lmer.eval$coefficients[5, "t value"],
    totXwait.p.value = lmer.chisq$`Pr(>Chisq)`[4],
    
    totXurg.estimate = lmer.eval$coefficients[6],
    totXurg.t.value = lmer.eval$coefficients[6, "t value"],
    totXurg.p.value = lmer.chisq$`Pr(>Chisq)`[5],
    
    waitXurg.estimate = lmer.eval$coefficients[7],
    waitXurg.t.value = lmer.eval$coefficients[7, "t value"],
    waitXurg.p.value = lmer.chisq$`Pr(>Chisq)`[6],
    
    totXwaitXurg.estimate = lmer.eval$coefficients[8],
    totXwaitXurg.t.value = lmer.eval$coefficients[8, "t value"],
    totXwaitXurg.p.value = lmer.chisq$`Pr(>Chisq)`[7],
    
    sigma.estimate = lmer.eval$sigma
  )
  
}
```

```{r eval=F}
# sample sizes
params$n.set <- c(30, 200, 300, 400)
# store the number of repetitions for the simulation (should usually be around 10.000)
params$n.sims <- 1000

# create data.table where each row is one simulation for one parameter values of interest
DT.sim.results2 <- CJ(sim.no = 1:params$n.sims,
                     n = params$n.set)

# for each simulation and sample size call the function to do the simulation
DT.sim.results2[, c('totTime.estimate', 'totTime.t.value', 'totTime.p.value',
                   'waitTime.estimate', 'waitTime.t.value', 'waitTime.p.value',
                   'urgency.estimate', 'urgency.t.value', 'urgency.p.value',
                   'totXwait.estimate', 'totXwait.t.value', 'totXwait.p.value',
                   'totXurg.estimate', 'totXurg.t.value', 'totXurg.p.value',
                   'waitXurg.estimate', 'waitXurg.t.value', 'waitXurg.p.value',
                   'totXwaitXurg.estimate', 'totXwaitXurg.t.value', 'totXwaitXurg.p.value',
                   'sigma.estimate') := 
                 LMM.sim.noslope(DT.bw.fact = DT.bw.fact, params = params, n = n), 
               by = .(sim.no, n)]

# calculate estimation errors
DT.sim.results2[, ':=' (totTime_estimation_error = totTime.estimate - params$beta.1,
                       waitTime_estimation_error = waitTime.estimate - params$beta.2,
                       urgency_estimation_error = urgency.estimate - params$beta.3,
                       totXwait_estimation_error = totXwait.estimate - params$beta.4,
                       totXurg_estimation_error = totXurg.estimate - params$beta.5,
                       waitXurg_estimation_error = waitXurg.estimate - params$beta.6,
                       totXwaitXurg_estimation_error = totXwaitXurg.estimate - params$beta.7,
                       sigma_estimation_error = sigma.estimate - params$sigma.epsilon)] 

# save simulated data
# write.csv(DT.sim.results2, "DT_simresults2.csv")
```

```{r}
# load data simulated without the random slope
DT.sim.results2 <- data.table(read.csv("DT_simresults2.csv"))
# set a factor to plot by sample size
DT.sim.results2[, n_fact := factor(n),]
# calc average estimation errors
DT.summary.sims2 <- DT.sim.results2[, lapply(.SD, mean), 
                                   .SDcols = c("totTime_estimation_error",
                                               "waitTime_estimation_error",
                                               "urgency_estimation_error",
                                               "totXwait_estimation_error",
                                               "totXurg_estimation_error",
                                               "waitXurg_estimation_error",
                                               "totXwaitXurg_estimation_error",
                                               "sigma_estimation_error"),
                                   by = n]
# calc proportions of significant p values
DT.summary.props2 <- DT.sim.results2[, lapply(.SD, propFun),
                                   .SDcols = c("totTime.p.value",
                                               "waitTime.p.value",
                                               "urgency.p.value",
                                               "totXwait.p.value",
                                               "totXurg.p.value",
                                               "waitXurg.p.value",
                                               "totXwaitXurg.p.value"),
                                   by = n]
```

```{r}
### 2-way effect ###
gp.violin.esti2.sim2 <- ggplot(DT.sim.results2, aes(x = n_fact, y = totXwait_estimation_error))

gp.violin.esti2.sim2 <- gp.violin.esti2.sim2 + geom_violin()
# add data
gp.violin.esti2.sim2 <- gp.violin.esti2.sim2 + geom_jitter(width = 0.1, 
                                                           alpha = 0.25, 
                                                           colour = 'blue')
# add horizontal line at 0
gp.violin.esti2.sim2 <- gp.violin.esti2.sim2 + geom_hline(aes(yintercept = 0), 
                                                        color = "black", size = 1)
# add axis labels
gp.violin.esti2.sim2 <- gp.violin.esti2.sim2 + ylab('Estimation Error for Total Time x Wait Time')
gp.violin.esti2.sim2 <- gp.violin.esti2.sim2 + xlab('Sample Size')
# add caption
gp.violin.esti2.sim2 <- gp.violin.esti2.sim2 + labs(caption = 
      "Estimation error for 1000 simulations of each sample size.")
# set theme
gp.violin.esti2.sim2 <- gp.violin.esti2.sim2 + theme_tufte(base_size = 11, base_family = "sans")
# align caption
gp.violin.esti2.sim2 <- gp.violin.esti2.sim2 + theme(plot.caption = element_text(hjust = 0))
# set coord
gp.violin.esti2.sim2 <- gp.violin.esti2.sim2 + coord_cartesian(ylim = c(-800,800))
```

```{r}
### 3-way effect ###
gp.violin.esti3.sim2 <- ggplot(DT.sim.results2, aes(x = n_fact, y = totXwaitXurg_estimation_error))

gp.violin.esti3.sim2 <- gp.violin.esti3.sim2 + geom_violin()
# add data
gp.violin.esti3.sim2 <- gp.violin.esti3.sim2 + geom_jitter(width = 0.1, 
                                                           alpha = 0.25,
                                                           colour = 'blue')
# add horizontal line at 0
gp.violin.esti3.sim2 <- gp.violin.esti3.sim2 + geom_hline(aes(yintercept = 0), 
                                                        color = "black", size = 1)
# add axis labels
gp.violin.esti3.sim2 <- gp.violin.esti3.sim2 + ylab('Estimation Error for Total Time x Wait Time x Urgency')
gp.violin.esti3.sim2 <- gp.violin.esti3.sim2 + xlab('Sample Size')

# set theme
gp.violin.esti3.sim2 <- gp.violin.esti3.sim2 + theme_tufte(base_size = 11, base_family = "sans")
# align caption
gp.violin.esti3.sim2 <- gp.violin.esti3.sim2 + theme(plot.caption = element_text(hjust = 0))
# set coord
gp.violin.esti3.sim2 <- gp.violin.esti3.sim2 + coord_cartesian(ylim = c(-800,800))
```

Figure 4

```{r fig.width=7, fig.height=4}
ggarrange(gp.violin.esti2.sim2, gp.violin.esti3.sim2, ncol = 2)
```
Table 4
```{r}
df.sim2.p.table <- format(round(DT.summary.props2,2),nsmall=2)
# set column names
colnames(df.sim2.p.table) <- c("Sample Size", "Total Time", "Wait Time", "Urgency",
                               "TotalxWait", "TotalxUrg", "WaitxUrg", "TotalxWaitxUrg")
# table of p value proportions
kbl(df.sim2.p.table, booktabs = T, align = c('r','r','r','r')) %>%
    footnote(general = "Proportion of significant p-values in 1000 simulations without simulated random slopes.",
             general_title = "Note.", footnote_as_chunk = T)

```
Table 5
```{r}
# make table data
df.sim2.est.table <- format(round(DT.summary.sims2,2),nsmall=2)
# set column names
colnames(df.sim2.est.table) <- c("Sample Size", "Total Time", "Wait Time", "Urgency",
                               "TotalxWait", "TotalxUrg", "WaitxUrg", "TotalxWaitxUrg",
                               "Residual")
# table of p value proportions
kbl(df.sim2.est.table, booktabs = T, align = c('r','r','r','r')) %>%
    footnote(general = "Mean Estimation Error in 1000 simulations without simulated random slopes..",
             general_title = "Note.", footnote_as_chunk = T)

```


## Simulation Three
The third simulation was designed to test whether the error in estimating the main effect of total time would result in significant *p*-values, when no real effect was simulated. Importantly, for this simulation, the interaction effects of total time with wait time, urgency, and the three-way interaction were included in the simulation.  
Simulation results (Figure 5, Table 6) suggest a near-certain likelihood of detecting a significant main effect of total time at the proposed sample size (*N* = 300), even when it was not simulated. However, the main effect would only be interpreted in the absence of interaction effects. The two-way interaction between total time and wait time was adequately powered (80%) and a near-certain likelihood of detecting a significant interaction between total time and wait time suggests low likelihood of concluding a false positive main effect of total time.  

```{r eval=F}
################
# SIMULATION 3 #
################
#### use random slope function with no total time effect ####
# fixed effects slopes
# the difference between the mean values of 35 mins and 25 mins
params$beta.1 <- (0)

# sample sizes
params$n.set <- c(30, 200, 300, 400)
# store the number of repetitions for the simulation (should usually be around 10.000)
params$n.sims <- 1000

# create data.table where each row is one simulation for one parameter values of interest
DT.sim.results3 <- CJ(sim.no = 1:params$n.sims,
                      n = params$n.set)

# for each simulation and sample size call the function to do the simulation
DT.sim.results3[, c('totTime.estimate', 'totTime.t.value', 'totTime.p.value',
                    'waitTime.estimate', 'waitTime.t.value', 'waitTime.p.value',
                    'urgency.estimate', 'urgency.t.value', 'urgency.p.value',
                    'totXwait.estimate', 'totXwait.t.value', 'totXwait.p.value',
                    'totXurg.estimate', 'totXurg.t.value', 'totXurg.p.value',
                    'waitXurg.estimate', 'waitXurg.t.value', 'waitXurg.p.value',
                    'totXwaitXurg.estimate', 'totXwaitXurg.t.value', 'totXwaitXurg.p.value',
                    'sigma.estimate') := 
                  LMM.sim.slope(DT.bw.fact = DT.bw.fact, params = params, n = n), 
                by = .(sim.no, n)]

# calculate estimation errors
DT.sim.results3[, ':=' (totTime_estimation_error = totTime.estimate - params$beta.1,
                        waitTime_estimation_error = waitTime.estimate - params$beta.2,
                        urgency_estimation_error = urgency.estimate - params$beta.3,
                        totXwait_estimation_error = totXwait.estimate - params$beta.4,
                        totXurg_estimation_error = totXurg.estimate - params$beta.5,
                        waitXurg_estimation_error = waitXurg.estimate - params$beta.6,
                        totXwaitXurg_estimation_error = totXwaitXurg.estimate - params$beta.7,
                        sigma_estimation_error = sigma.estimate - params$sigma.epsilon)] 
# save simulated data
#write.csv(DT.sim.results3, "DT_simresults3.csv")
```

```{r}
# set wd
#setwd("")
# load data simulated without the main effect of total time
DT.sim.results3 <- data.table(read.csv("DT_simresults3.csv"))
# set a factor to plot by sample size
DT.sim.results3[, n_fact := factor(n),]
# calc average estimation errors
DT.summary.sims3 <- DT.sim.results3[, lapply(.SD, mean), 
                                   .SDcols = c("totTime_estimation_error",
                                               "waitTime_estimation_error",
                                               "urgency_estimation_error",
                                               "totXwait_estimation_error",
                                               "totXurg_estimation_error",
                                               "waitXurg_estimation_error",
                                               "totXwaitXurg_estimation_error",
                                               "sigma_estimation_error"),
                                   by = n]
# calc proportions of significant p values
DT.summary.props3 <- DT.sim.results3[, lapply(.SD, propFun),
                                   .SDcols = c("totTime.p.value",
                                               "waitTime.p.value",
                                               "urgency.p.value",
                                               "totXwait.p.value",
                                               "totXurg.p.value",
                                               "waitXurg.p.value",
                                               "totXwaitXurg.p.value"),
                                   by = n]
```

```{r}
### two-way interaction p-values ###
# ggplot data layer
gp.hist.totTimeFP <- ggplot(DT.sim.results3)
# add histograms
gp.hist.totTimeFP <- gp.hist.totTimeFP + geom_histogram(position = "dodge", bins = 15,
                                              aes(x = totXwait.p.value, 
                                                  fill = n_fact))
# add vert line for sig value
gp.hist.totTimeFP <- gp.hist.totTimeFP + geom_vline(aes(xintercept = 0.05), 
                                          color = "red", size = 1) 
# add horizontal line for number of p-values expected w/o effect
gp.hist.totTimeFP <- gp.hist.totTimeFP + geom_hline(aes(yintercept = (1000*0.05)), 
                                          color = "blue", size = 1) 
# set theme tufte
gp.hist.totTimeFP <- gp.hist.totTimeFP + theme_tufte(base_size = 11, base_family = "sans") 
# format legend and colors
gp.hist.totTimeFP <- gp.hist.totTimeFP + scale_fill_manual(name = "Sample Size",
                              labels = c('N = 30',
                                         'N = 200',
                                         'N = 300',
                                         'N = 400'),
                              values = c('lightblue', 'palegreen',
                                         'gold', 'pink2'))
# add axis labels
gp.hist.totTimeFP <- gp.hist.totTimeFP + xlab("Total Time: No Effect Simulated")
gp.hist.totTimeFP <- gp.hist.totTimeFP + ylab("Number of Significant P-values")
# add caption
gp.hist.totTimeFP <- gp.hist.totTimeFP + labs(caption = 
      "Of 1000 simulations, the number of significant p-values for each sample size. \n
      Interaction effects were simulated, but the main effect above was not.  \n
      Simulations to the left of the red line are significant. \n
      The blue line is the expected number of significant p-values.")
# align caption
gp.hist.totTimeFP <- gp.hist.totTimeFP + theme(plot.caption = element_text(hjust = 0, 
                                                                           lineheight = 0.5))
```

```{r}
### two-way interaction p-values ###
# ggplot data layer
gp.hist.2way.3 <- ggplot(DT.sim.results3)
# add histograms
gp.hist.2way.3 <- gp.hist.2way.3 + geom_histogram(position = "dodge", bins = 15,
                                              aes(x = totXwait.p.value, 
                                                  fill = n_fact))
# add vert line for sig value
gp.hist.2way.3 <- gp.hist.2way.3 + geom_vline(aes(xintercept = 0.05), 
                                          color = "red", size = 1) 
# add horizontal line for number of p-values expected w/o effect
gp.hist.2way.3 <- gp.hist.2way.3 + geom_hline(aes(yintercept = (1000*0.05)), 
                                          color = "blue", size = 1) 
# set theme tufte
gp.hist.2way.3 <- gp.hist.2way.3 + theme_tufte(base_size = 11, base_family = "sans") 
# format legend and colors
gp.hist.2way.3 <- gp.hist.2way.3 + scale_fill_manual(name = "Sample Size",
                              labels = c('N = 30',
                                         'N = 200',
                                         'N = 300',
                                         'N = 400'),
                              values = c('lightblue', 'palegreen',
                                         'gold', 'pink2'))
# add axis labels
gp.hist.2way.3 <- gp.hist.2way.3 + xlab("Total Time x Wait Time Interaction")
gp.hist.2way.3 <- gp.hist.2way.3 + ylab("Number of Significant P-values")
# add caption
gp.hist.2way.3 <- gp.hist.2way.3 + labs(caption = 
      "Of 1000 simulations, the number of significant p-values for each sample size. \n
      Simulations to the left of the red line are significant. \n
      The blue line is the expected number of significant p-values if there were no effect.")
# align caption
gp.hist.2way.3 <- gp.hist.2way.3 + theme(plot.caption = element_text(hjust = 0, lineheight = 0.5))
```

Figure 5

```{r fig.width=7, fig.height=6}
ggarrange(gp.hist.totTimeFP, gp.hist.2way.3)
```

Table 6
```{r}
df.sim3.p.table <- format(round(DT.summary.props3,2),nsmall=2)
# set column names
colnames(df.sim3.p.table) <- c("Sample Size", "Total Time", "Wait Time", "Urgency",
                               "TotalxWait", "TotalxUrg", "WaitxUrg", "TotalxWaitxUrg")
# table of p value proportions
kbl(df.sim3.p.table, booktabs = T, align = c('r','r','r','r')) %>%
    footnote(general = "Proportion of significant p-values in 1000 simulations with no main effect of total time simulated.",
             general_title = "Note.", footnote_as_chunk = T)

```

## Simulation Four
The fourth simulation was designed to test whether the error in estimating the main effect of total time would result in significant *p*-values, when no real effect was simulated. Importantly, for this simulation, the interaction effects of total time with urgency, and the three-way interaction were **not** included in the simulation. Only the interaction between total time and wait time was simulated.  
The simulation results (Figure 6, Table 7) suggest that a erroneously significant main effect of total time would be detected 50% of the time, even when it was not simulated. However, the main effect would only be interpreted in the absence of interaction effects. Only the two-way interaction between total time and wait time was simulated, and that effect would also be detected 50% of the time. This simulation suggests moderate likelihood of concluding a false positive main effect of total time when it was not simulated.  

```{r eval=F}
################
# SIMULATION 4 #
################
#### use random slope function with no total time effect ####
# and only one interaction - between subjects total time by wait time #
# fixed effects slopes
# the difference between the mean values of 35 mins and 25 mins
params$beta.1 <- 0
# slope of the fifth predictor, the interaction between the first dummy of x1 and the first dummy of x3
# the change in the difference between either x1-level 1.1 and x1-level 1.2 with
# a change from x3-level 3.1 to x3-level 3.2 or vice versa
params$beta.5 <- 0
# slope of the seventh predictor, the interaction between the first dummy of x1 and the first dummy of x3
# the change in the difference between either x1-level 1.1 and x1-level 1.2 with
# a change from x3-level 2.1 to x3-level 2.2 and
# a change from x3-level 3.1 to x3-level 3.2 or vice versa
params$beta.7 <- 0

# sample sizes
params$n.set <- c(30, 200, 300, 400)
# store the number of repetitions for the simulation (should usually be around 10.000)
params$n.sims <- 1000

# create data.table where each row is one simulation for one parameter values of interest
DT.sim.results4 <- CJ(sim.no = 1:params$n.sims,
                      n = params$n.set)

# for each simulation and sample size call the function to do the simulation
DT.sim.results4[, c('totTime.estimate', 'totTime.t.value', 'totTime.p.value',
                    'waitTime.estimate', 'waitTime.t.value', 'waitTime.p.value',
                    'urgency.estimate', 'urgency.t.value', 'urgency.p.value',
                    'totXwait.estimate', 'totXwait.t.value', 'totXwait.p.value',
                    'totXurg.estimate', 'totXurg.t.value', 'totXurg.p.value',
                    'waitXurg.estimate', 'waitXurg.t.value', 'waitXurg.p.value',
                    'totXwaitXurg.estimate', 'totXwaitXurg.t.value', 'totXwaitXurg.p.value',
                    'sigma.estimate') := 
                  LMM.sim.slope(DT.bw.fact = DT.bw.fact, params = params, n = n), 
                by = .(sim.no, n)]

# calculate estimation errors
DT.sim.results4[, ':=' (totTime_estimation_error = totTime.estimate - params$beta.1,
                        waitTime_estimation_error = waitTime.estimate - params$beta.2,
                        urgency_estimation_error = urgency.estimate - params$beta.3,
                        totXwait_estimation_error = totXwait.estimate - params$beta.4,
                        totXurg_estimation_error = totXurg.estimate - params$beta.5,
                        waitXurg_estimation_error = waitXurg.estimate - params$beta.6,
                        totXwaitXurg_estimation_error = totXwaitXurg.estimate - params$beta.7,
                        sigma_estimation_error = sigma.estimate - params$sigma.epsilon)] 
# save simulated data
#write.csv(DT.sim.results4, "DT_simresults4.csv")
```

```{r}
# set wd
#setwd("")
# load data simulated without the main effect of total time
DT.sim.results4 <- data.table(read.csv("DT_simresults4.csv"))
# set a factor to plot by sample size
DT.sim.results4[, n_fact := factor(n),]
# calc average estimation errors
DT.summary.sims4 <- DT.sim.results4[, lapply(.SD, mean), 
                                   .SDcols = c("totTime_estimation_error",
                                               "waitTime_estimation_error",
                                               "urgency_estimation_error",
                                               "totXwait_estimation_error",
                                               "totXurg_estimation_error",
                                               "waitXurg_estimation_error",
                                               "totXwaitXurg_estimation_error",
                                               "sigma_estimation_error"),
                                   by = n]
# calc proportions of significant p values
DT.summary.props4 <- DT.sim.results4[, lapply(.SD, propFun),
                                   .SDcols = c("totTime.p.value",
                                               "waitTime.p.value",
                                               "urgency.p.value",
                                               "totXwait.p.value",
                                               "totXurg.p.value",
                                               "waitXurg.p.value",
                                               "totXwaitXurg.p.value"),
                                   by = n]
```

```{r}
### two-way interaction p-values ###
# ggplot data layer
gp.hist.totTimeFP2 <- ggplot(DT.sim.results4)
# add histograms
gp.hist.totTimeFP2 <- gp.hist.totTimeFP2 + geom_histogram(position = "dodge", bins = 15,
                                              aes(x = totXwait.p.value, 
                                                  fill = n_fact))
# add vert line for sig value
gp.hist.totTimeFP2 <- gp.hist.totTimeFP2 + geom_vline(aes(xintercept = 0.05), 
                                          color = "red", size = 1) 
# add horizontal line for number of p-values expected w/o effect
gp.hist.totTimeFP2 <- gp.hist.totTimeFP2 + geom_hline(aes(yintercept = (1000*0.05)), 
                                          color = "blue", size = 1) 
# set theme tufte
gp.hist.totTimeFP2 <- gp.hist.totTimeFP2 + theme_tufte(base_size = 11, base_family = "sans") 
# format legend and colors
gp.hist.totTimeFP2 <- gp.hist.totTimeFP2 + scale_fill_manual(name = "Sample Size",
                              labels = c('N = 30',
                                         'N = 200',
                                         'N = 300',
                                         'N = 400'),
                              values = c('lightblue', 'palegreen',
                                         'gold', 'pink2'))
# add axis labels
gp.hist.totTimeFP2 <- gp.hist.totTimeFP2 + xlab("Total Time: No Effect Simulated")
gp.hist.totTimeFP2 <- gp.hist.totTimeFP2 + ylab("Number of Significant P-values")
# add caption
gp.hist.totTimeFP2 <- gp.hist.totTimeFP2 + labs(caption = 
      "Of 1000 simulations, the number of significant p-values for each sample size. \n
      Interaction effects were simulated, but the plotted main effect was not.  \n
      Simulations to the left of the red line are significant. \n
      The blue line is the expected number of significant p-values.")
# align caption
gp.hist.totTimeFP2 <- gp.hist.totTimeFP2 + theme(plot.caption = element_text(hjust = 0, 
                                                                           lineheight = 0.5))
```

```{r}
### two-way interaction p-values ###
# ggplot data layer
gp.hist.2way.4 <- ggplot(DT.sim.results3)
# add histograms
gp.hist.2way.4 <- gp.hist.2way.4 + geom_histogram(position = "dodge", bins = 15,
                                              aes(x = totXwait.p.value, 
                                                  fill = n_fact))
# add vert line for sig value
gp.hist.2way.4 <- gp.hist.2way.4 + geom_vline(aes(xintercept = 0.05), 
                                          color = "red", size = 1) 
# add horizontal line for number of p-values expected w/o effect
gp.hist.2way.4 <- gp.hist.2way.4 + geom_hline(aes(yintercept = (1000*0.05)), 
                                          color = "blue", size = 1) 
# set theme tufte
gp.hist.2way.4 <- gp.hist.2way.4 + theme_tufte(base_size = 11, base_family = "sans") 
# format legend and colors
gp.hist.2way.4 <- gp.hist.2way.4 + scale_fill_manual(name = "Sample Size",
                              labels = c('N = 30',
                                         'N = 200',
                                         'N = 300',
                                         'N = 400'),
                              values = c('lightblue', 'palegreen',
                                         'gold', 'pink2'))
# add axis labels
gp.hist.2way.4 <- gp.hist.2way.4 + xlab("Total Time x Wait Time Interaction")
gp.hist.2way.4 <- gp.hist.2way.4 + ylab("Number of Significant P-values")
# add caption
gp.hist.2way.4 <- gp.hist.2way.4 + labs(caption = 
      "Of 1000 simulations, the number of significant p-values for each sample size. \n
      Simulations to the left of the red line are significant. \n
      The blue line is the expected number of significant p-values if there were no effect.")
# align caption
gp.hist.2way.4 <- gp.hist.2way.4 + theme(plot.caption = element_text(hjust = 0, lineheight = 0.5))
```

Figure 6

```{r fig.width=7, fig.height=6}
ggarrange(gp.hist.totTimeFP2, gp.hist.2way.4)
```

Table 7
```{r}
df.sim4.p.table <- format(round(DT.summary.props4,2),nsmall=2)
# set column names
colnames(df.sim4.p.table) <- c("Sample Size", "Total Time", "Wait Time", "Urgency",
                               "TotalxWait", "TotalxUrg", "WaitxUrg", "TotalxWaitxUrg")
# table of p value proportions
kbl(df.sim4.p.table, booktabs = T, align = c('r','r','r','r')) %>%
    footnote(general = "Proportion of significant p-values in 1000 simulations - only total by wait time interaction simulated.",
             general_title = "Note.", footnote_as_chunk = T)

```

## Simulation Five
The fifth simulation was designed to test whether the error in estimating the main effect of total time would result in significant *p*-values, when no real effect was simulated. Importantly, for this simulation, **no** interaction effects of total time were included in the simulation.  

The simulation results (Figure 7, Table 8) suggest that a significant main effect of total time would not be detected at greater than 5% chance when it was not simulated, in the absence of simulated interaction effects. This simulation suggests little likelihood of concluding a false positive main effect of total time when it was not simulated, so long as none of the other fixed effects had an interactive effect with total time.

```{r eval=F}
################
# SIMULATION 5 #
################
# fixed effects slopes
# the difference between the mean values of 35 mins and 25 mins
params$beta.1 <- 0
# slope of the fourth predictor, the interaction between the first dummy of x1 and the first dummy of x2
# the change in the difference between either x1-level 1.1 and x1-level 1.2 with
# a change from x2-level 2.1 to x2-level 2.2 or vice versa
params$beta.4 <- 0
# slope of the fifth predictor, the interaction between the first dummy of x1 and the first dummy of x3
# the change in the difference between either x1-level 1.1 and x1-level 1.2 with
# a change from x3-level 3.1 to x3-level 3.2 or vice versa
params$beta.5 <- 0
# slope of the seventh predictor, the interaction between the first dummy of x1 and the first dummy of x3
# the change in the difference between either x1-level 1.1 and x1-level 1.2 with
# a change from x3-level 2.1 to x3-level 2.2 and
# a change from x3-level 3.1 to x3-level 3.2 or vice versa
params$beta.7 <- 0

# sample sizes
params$n.set <- c(30, 200, 300, 400)
# store the number of repetitions for the simulation (should usually be around 10.000)
params$n.sims <- 1000

# create data.table where each row is one simulation for one parameter values of interest
DT.sim.results5 <- CJ(sim.no = 1:params$n.sims,
                      n = params$n.set)

# for each simulation and sample size call the function to do the simulation
DT.sim.results5[, c('totTime.estimate', 'totTime.t.value', 'totTime.p.value',
                    'waitTime.estimate', 'waitTime.t.value', 'waitTime.p.value',
                    'urgency.estimate', 'urgency.t.value', 'urgency.p.value',
                    'totXwait.estimate', 'totXwait.t.value', 'totXwait.p.value',
                    'totXurg.estimate', 'totXurg.t.value', 'totXurg.p.value',
                    'waitXurg.estimate', 'waitXurg.t.value', 'waitXurg.p.value',
                    'totXwaitXurg.estimate', 'totXwaitXurg.t.value', 'totXwaitXurg.p.value',
                    'sigma.estimate') := 
                  LMM.sim.slope(DT.bw.fact = DT.bw.fact, params = params, n = n), 
                by = .(sim.no, n)]

# calculate estimation errors
DT.sim.results5[, ':=' (totTime_estimation_error = totTime.estimate - params$beta.1,
                        waitTime_estimation_error = waitTime.estimate - params$beta.2,
                        urgency_estimation_error = urgency.estimate - params$beta.3,
                        totXwait_estimation_error = totXwait.estimate - params$beta.4,
                        totXurg_estimation_error = totXurg.estimate - params$beta.5,
                        waitXurg_estimation_error = waitXurg.estimate - params$beta.6,
                        totXwaitXurg_estimation_error = totXwaitXurg.estimate - params$beta.7,
                        sigma_estimation_error = sigma.estimate - params$sigma.epsilon)] 
# save simulated data
#write.csv(DT.sim.results5, "DT_simresults5.csv")
```

```{r}
# set wd
# setwd("")
# load data simulated without the main effect of total time
DT.sim.results5 <- data.table(read.csv("DT_simresults5.csv"))
# set a factor to plot by sample size
DT.sim.results5[, n_fact := factor(n),]
# calc average estimation errors
DT.summary.sims5 <- DT.sim.results5[, lapply(.SD, mean), 
                                   .SDcols = c("totTime_estimation_error",
                                               "waitTime_estimation_error",
                                               "urgency_estimation_error",
                                               "totXwait_estimation_error",
                                               "totXurg_estimation_error",
                                               "waitXurg_estimation_error",
                                               "totXwaitXurg_estimation_error",
                                               "sigma_estimation_error"),
                                   by = n]
# calc proportions of significant p values
DT.summary.props5 <- DT.sim.results5[, lapply(.SD, propFun),
                                   .SDcols = c("totTime.p.value",
                                               "waitTime.p.value",
                                               "urgency.p.value",
                                               "totXwait.p.value",
                                               "totXurg.p.value",
                                               "waitXurg.p.value",
                                               "totXwaitXurg.p.value"),
                                   by = n]
```

```{r}
### two-way interaction p-values ###
# ggplot data layer
gp.hist.totTimeFP3 <- ggplot(DT.sim.results5)
# add histograms
gp.hist.totTimeFP3 <- gp.hist.totTimeFP3 + geom_histogram(position = "dodge", bins = 15,
                                              aes(x = totXwait.p.value, 
                                                  fill = n_fact))
# add vert line for sig value
gp.hist.totTimeFP3 <- gp.hist.totTimeFP3 + geom_vline(aes(xintercept = 0.05), 
                                          color = "red", size = 1) 
# add horizontal line for number of p-values expected w/o effect
gp.hist.totTimeFP3 <- gp.hist.totTimeFP3 + geom_hline(aes(yintercept = (1000*0.05)), 
                                          color = "blue", size = 1) 
# set theme tufte
gp.hist.totTimeFP3 <- gp.hist.totTimeFP3 + theme_tufte(base_size = 11, base_family = "sans") 
# format legend and colors
gp.hist.totTimeFP3 <- gp.hist.totTimeFP3 + scale_fill_manual(name = "Sample Size",
                              labels = c('N = 30',
                                         'N = 200',
                                         'N = 300',
                                         'N = 400'),
                              values = c('lightblue', 'palegreen',
                                         'gold', 'pink2'))
# add axis labels
gp.hist.totTimeFP3 <- gp.hist.totTimeFP3 + xlab("Total Time: No Effect in Simulated Data")
gp.hist.totTimeFP3 <- gp.hist.totTimeFP3 + ylab("Number of Significant P-values")
# add caption
gp.hist.totTimeFP3 <- gp.hist.totTimeFP3 + labs(caption = 
      "Of 1000 simulations, the number of significant p-values for each sample size. \n
      No main or interactive effects with total time were simulated.  \n
      Simulations to the left of the red line are significant. \n
      The blue line is the expected number of significant p-values.")
# align caption
gp.hist.totTimeFP3 <- gp.hist.totTimeFP3 + theme(plot.caption = element_text(hjust = 0, 
                                                                           lineheight = 0.5))
```

```{r}
### two-way interaction p-values ###
# ggplot data layer
gp.hist.2way.5 <- ggplot(DT.sim.results5)
# add histograms
gp.hist.2way.5 <- gp.hist.2way.5 + geom_histogram(position = "dodge", bins = 15,
                                              aes(x = totXwait.p.value, 
                                                  fill = n_fact))
# add vert line for sig value
gp.hist.2way.5 <- gp.hist.2way.5 + geom_vline(aes(xintercept = 0.05), 
                                          color = "red", size = 1) 
# add horizontal line for number of p-values expected w/o effect
gp.hist.2way.5 <- gp.hist.2way.5 + geom_hline(aes(yintercept = (1000*0.05)), 
                                          color = "blue", size = 1) 
# set theme tufte
gp.hist.2way.5 <- gp.hist.2way.5 + theme_tufte(base_size = 11, base_family = "sans") 
# format legend and colors
gp.hist.2way.5 <- gp.hist.2way.5 + scale_fill_manual(name = "Sample Size",
                              labels = c('N = 30',
                                         'N = 200',
                                         'N = 300',
                                         'N = 400'),
                              values = c('lightblue', 'palegreen',
                                         'gold', 'pink2'))
# add axis labels
gp.hist.2way.5 <- gp.hist.2way.5 + xlab("Total Time x Wait Time Interaction")
gp.hist.2way.5 <- gp.hist.2way.5 + ylab("Number of Significant P-values")
# add caption
gp.hist.2way.5 <- gp.hist.2way.5 + labs(caption = 
      "Of 1000 simulations, the number of significant p-values for each sample size. \n
      Simulations to the left of the red line are significant. \n
      The blue line is the expected number of significant p-values if there were no effect.")
# align caption
gp.hist.2way.5 <- gp.hist.2way.5 + theme(plot.caption = element_text(hjust = 0, lineheight = 0.5))
```

Figure 7

```{r fig.width=7, fig.height=6}
ggarrange(gp.hist.totTimeFP3, gp.hist.2way.5)
```
Table 8
```{r}
df.sim5.p.table <- format(round(DT.summary.props5,2),nsmall=2)
# set column names
colnames(df.sim5.p.table) <- c("Sample Size", "Total Time", "Wait Time", "Urgency",
                               "TotalxWait", "TotalxUrg", "WaitxUrg", "TotalxWaitxUrg")
# table of p value proportions
kbl(df.sim5.p.table, booktabs = T, align = c('r','r','r','r')) %>%
    footnote(general = "Proportion of significant p-values in 1000 simulations - no effects of total time simulated.",
             general_title = "Note.", footnote_as_chunk = T)

```

## Simulation Conclusion
The results of simulations one and two suggest that the linear mixed-effects model without a random slope of urgency by participant performed similarly whether or not the slope was present in the simulated data. The results of simulations three through five suggest that there was a chance of concluding a main effect of total time, if there was no true effect in the simulated data, if an interaction was simulated in the data. Specifically, simulation four suggested that if there was a two-way interaction between total time and waiting time on planning time, there was a roughly 50% chance of detecting the effect and a roughly 25% chance of concluding a nonexistent main effect of total time (given that the main effect would only be interpreted in the absence of an interaction and there was a 50% chance of a significant main effect and a significant interaction effect). Importantly, these conclusions were based on simulated analyses using purely hypothetical parameters.







